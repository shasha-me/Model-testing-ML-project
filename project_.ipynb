{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E2q5a6E5-E5"
      },
      "source": [
        "# these are the libraries which we would use but pandas is used very rare\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xOiDfMy7Rcs"
      },
      "source": [
        " **To explore the the data :**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        " *The data set is included in scikit-learn in database module*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hQNYOCl7Cau"
      },
      "source": [
        "#we can load it by calling load_iris function\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWwvvfth8u0r"
      },
      "source": [
        "*This iris return a bunch object , which is similar to dictionary(contains keys and values)*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Ov1B5J9Qjr",
        "outputId": "6f703a62-5e5c-4e65-ba11-8203ab8441af"
      },
      "source": [
        "#the following code will show all the keys(its a term referred with dictionary) of the dataset which we have used in this project\n",
        "\n",
        "print(\"Keys of iris_dataset: \\n{}\".format(iris_dataset.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys of iris_dataset: \n",
            "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daENobLw-bwx"
      },
      "source": [
        "**Now lets see every keys which are included in the data set :**\n",
        "\n",
        "1.  *First we will start with the* **DESCR** : *this key provides the description of the datasets*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2dtGXII_fm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29287a10-fdd8-4c94-bac2-3f0970f6b9b4"
      },
      "source": [
        "# here we are printing only 200 characteristics (193 in video session) using the slicing method\n",
        "\n",
        "print(iris_dataset['DESCR'][:200] + \"\\n...\" )\n",
        "# this is a one line code\n",
        "\n",
        "#the above code can be written in begginer freindly way\n",
        "\n",
        "#val = iris_dataset['DESCR']\n",
        "#start_val = val[:200]\n",
        "#print( start_val + \"\\n...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, predictive\n",
            "...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4poyrUCDBpb"
      },
      "source": [
        "2. *We will proceed to* **target_names** : *contains the species of flower that we want to predict i.e. 'setosa' 'versicolor' and 'virginica'*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQSiEYLxDihx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a081ee47-1e91-444d-89c1-9c41b2aafb08"
      },
      "source": [
        "# printing the target names with format feature of python\n",
        "\n",
        "print(\"Target names: {}\".format(iris_dataset['target_names']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target names: ['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj0ODJKvEkmh"
      },
      "source": [
        "3. *Now we are heading with* **feature_names** : *gives the description of each feature it includes the 'sepal length', 'sepal width', 'petal length' and the 'petal width' all in centimeters.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnUoZRRIFUW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb219941-c766-4c1f-f488-b438a5abebb8"
      },
      "source": [
        "# again using format specification of python\n",
        "\n",
        "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names'])) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature names: \n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDyLcBIhHtF5"
      },
      "source": [
        "4. *Heading ahead with* **data** : *contains numeric measurements of sepal length, sepal width, petal length, and petal width in a NumPy array*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upskS-DEJLmG",
        "outputId": "7d9d1c3d-3c45-4244-e80c-c7c36135b58e"
      },
      "source": [
        "# this will print the type of key-\"data'\n",
        "\n",
        "print( \"Type of data : {}\".format(type(iris_dataset['data'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of data : <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb_CNJkIMHX0"
      },
      "source": [
        "*The shape of the data array is the number of samples multiplied by the number of features. This is a convention in scikit-learn, and your data will always be assumed to be in this shape*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWngRT5HLOmN",
        "outputId": "a5f8897e-487e-4474-ce7d-ba9cc9d13c9f"
      },
      "source": [
        "#this will print the shape (whether it's a 1-day array or 2-d or any other) of the data\n",
        "\n",
        "print(\"Shape of the data: {}\".format(iris_dataset['data'].shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the data: (150, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duI7CjRFL9jF"
      },
      "source": [
        "-------**data** key is a **two-dimensional array**------\n",
        "\n",
        "The rows in this data array corrrespond to the flowers, while the columns represent the four measurements that were taken for each flower"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAaErmR8M2CB"
      },
      "source": [
        "*Here are the feature values for the first five samples:*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qS0IauEyNS3q",
        "outputId": "98f32f38-f3f9-4586-e055-e7428635ddf6"
      },
      "source": [
        "# printing will be done using slicing way to print 5 samples from 150 samples\n",
        "\n",
        "print(\"First five columns of data: \\n{}\".format(iris_dataset['data'][:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First five columns of data: \n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr971PeHOYR5"
      },
      "source": [
        "5. Now lets come to **target** key : contains the species of each flowers that were measured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYaaZHw-O2kf",
        "outputId": "3342442a-9e05-4e9c-d5ba-a71e1accbece"
      },
      "source": [
        "# this will print the type of key-\"data'\n",
        "\n",
        "print( \"Type of target : {}\".format(type(iris_dataset['target'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of target : <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EODKj5QPS3lh"
      },
      "source": [
        "**target** is a **one-dimensional array**, and on seeing the **shape** we can see that it contains **one entry per flower**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6smV2o9TbG8",
        "outputId": "5c0a4591-2279-4807-ce07-86c098029672"
      },
      "source": [
        "#this will print the shape  of the target\n",
        "\n",
        "print(\"Shape of the target: {}\".format(iris_dataset['target'].shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the target: (150,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH3v50BI5rOT"
      },
      "source": [
        "On seeing the target key and exploring the values we can easily see that The Species are enclosed as integers from 0 to 2:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QibTCAA5T2uE",
        "outputId": "dbca25ad-ccbb-4d5a-ae29-604dd6b9b4a4"
      },
      "source": [
        "# print the values of \"target\" key\n",
        "print(\"Target: \\n{}\".format(iris_dataset['target']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: \n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvC17onyUQ0v"
      },
      "source": [
        "*The meanings of above values :* \n",
        "\n",
        "a)  **0** means **setosa**\n",
        "\n",
        "b)  **1** means **versicolor**\n",
        "\n",
        "c)  **2** means **virginica** \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f_eUPNXUrLC"
      },
      "source": [
        "**TRAIN AND TESTING OF MODEL**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We will now first train the model and test if its working fine or not"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo6ujViIVHIJ"
      },
      "source": [
        "*We are  going to import scikit-learn to, here in the below code :-*\n",
        "\n",
        "X(capital) - Denoted for **data** / Its two dimensional array (a matrix)\n",
        "\n",
        "y(lowercase) - denotes **labels** / Its one- dimensional array(a vector)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIrWN5LejvcU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NywIjOLDqmdZ"
      },
      "source": [
        "*Before making the split, the train_test_split function shuffles the dataset using a pseudorandom number generator. To make sure that we will get the same output if we run the same function several times, we provide the pseudorandom number generator with a fixed seed using the random_state parameter.*\n",
        "\n",
        "The output of the train_test_split function is X_test,X_train,y_test and y_train, which all are NumPy arrays. X_train contains 75% of the rows of the dataset, abd X_test contains the remaining 25%. We will see all the piece of this paragraph with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voa3Tu2X3hJ8",
        "outputId": "6bb20bbd-c612-404a-f0b5-58b48c4e3b26"
      },
      "source": [
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (112, 4)\n",
            "y_train shape: (112,)\n",
            "X_test shape: (38, 4)\n",
            "y_test shape: (38,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVCFUZmw7D6w"
      },
      "source": [
        " ***INSPECTING THE DATA***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODAR0ai6p3Kk"
      },
      "source": [
        "Now we start the real machine learning model. This model can be solved with many classification model but we are using the k-nearest neighbours classifier.\n",
        "\n",
        "**k-nearest neighbours classifier : ** *In this clssification algorithm, to make prediction of a new data point, the classifier finds the point in the training set that is closest to the new point. Then this assigns the label of this training point to the new data point.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf2RIjIToid9"
      },
      "source": [
        "#The most important parameter of KneighboursClassifier is the number of neighbours, which we will set 1\n",
        "# this code is to import KNeighborsClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn=KNeighborsClassifier(n_neighbors=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qQOsa6Kp5jS"
      },
      "source": [
        "knn will hold the information that the algorithm has extracted from the training data. The KneighborsClassification will only store the information \n",
        "\n",
        "*To build the model on the training set we call the fit method of the knn object :*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdrXEAe2rHm4",
        "outputId": "f92f6519-44b6-4511-a3ac-030a96955341"
      },
      "source": [
        "# knn object,takes as argument the NumPy array X_train containing the training sata and the NumPy array y_train of the corresponding training \n",
        "#labels:\n",
        "# This code is training the model \n",
        "knn.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFFR3mFXvNzz"
      },
      "source": [
        "**MAKING PREDICTIONS**\n",
        "\n",
        "---\n",
        "We have trained the model now we are gonna predict that the model is running good or not\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLbj4VCXvstd",
        "outputId": "9da98d18-6f00-454b-8c99-d03372f4b2d6"
      },
      "source": [
        "# Here we are providing an unknown flowers featuers that are : sepal_lenth=5cm,sepal width=2.9cm petal length=1cm,petal width=0.2cm\n",
        "# we will put these data into a numPy array, calculating the shape (no_of_samples(1) x no_of_features(4))\n",
        "\n",
        "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
        "print(\"X_new shape: {}\".format(X_new.shape))\n",
        "\n",
        "# we accept the argument of np.array as two dimensional because scikit-learn always expects two dimensional arrrays of data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_new shape: (1, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbzG-YQmxzN4"
      },
      "source": [
        "*To make prediction we call the predict method of the knn object*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKUBmLuAx9R1",
        "outputId": "7aa564e8-4d8a-4aeb-e85f-38be6788be95"
      },
      "source": [
        "prediction = knn.predict(X_new)\n",
        "\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Predicted target name: {}\".format(iris_dataset['target_names'][prediction]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: [0]\n",
            "Predicted target name: ['setosa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmZ25aRe1Dob"
      },
      "source": [
        "**EVALUATING THE MODEL**\n",
        "\n",
        "---\n",
        "We can now measure how well th emodel works by computing the accuracy, which is the fraction of flowers for which the right species was predicted:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOA0EC0T1kOK",
        "outputId": "33633091-864c-4e0a-da62-0d080da939e4"
      },
      "source": [
        "y_pred=knn.predict(X_test)\n",
        "print(\"Test set predictions :\\n {}\".format(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set predictions :\n",
            " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
            " 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ickPnjtI2tUf",
        "outputId": "db6e7526-efc8-40a3-acf9-3683b31b0497"
      },
      "source": [
        "# now we will check if the predicted value is same as that of assigned values\n",
        "print(\"Test set score : {}\".format(np.mean(y_pred == y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set score : 0.9736842105263158\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpymcfUu5Fxy"
      },
      "source": [
        "*So, At last we got our **model** with aprroximately **97% accuracy** which is a appreciable work*"
      ]
    }
  ]
}